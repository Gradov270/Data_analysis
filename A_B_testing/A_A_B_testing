import pandas as pd #импорт библиотек
import datetime
import matplotlib.pyplot as plt
from plotly import graph_objects as go 
from scipy import stats as st
from scipy import stats as st
import numpy as np
import math as mth

df = df.rename(columns = {'EventName':'event_name','DeviceIDHash':'device_id_hash','EventTimestamp':'event_timestamp','ExpId':'exp_id',})
#переименовал названия столбцов для удобства с пробелами

df.duplicated().sum() #число строк дубликатов
round(df.duplicated().sum()*100/df.shape[0], 2) #доля дубликатов от всего датафрейма

df = df.drop_duplicates()
df['event_name'].value_counts() #неявных дубликатов нет. Нет необходимости приводить к нижнему регистру

df['exp_id'].value_counts() #Лишних данных нет

df['date_time'] = pd.to_datetime(df['event_timestamp'], utc=True, unit='s') #переводим данные из секунд в дату
df['date'] = df['date_time'].dt.date #отбираем дату

data = {'event_name':df['event_name'].unique(), 
       'russian_translation':['Появление Главного Экрана','Появление предложений На Экране','Появление на Экране Корзины','Появление на Экране Сообщения "Оплата прошла успешно"', 'Руководство']}
#создаю датафрейм с переводом наименований событий на русский язык 

events = pd.DataFrame(data)

len(df['device_id_hash'].unique()) #количество пользователей

table_group_1 = df.groupby('device_id_hash').agg({'event_name':'count'}) #посчитаем, сколько событий приходится на каждого пользователя

mean_events_per_user = round(table_group_1['event_name'].sum()/len(table_group_1.index))

mean_events_per_user_median = round(table_group_1['event_name'].median())

df['date_time'].min()
df['date_time'].max()

df['date_time'].hist(bins=14)
plt.xticks(rotation = 45)
plt.show() #визуализация частот событий по датам

df_filter=df.loc[df['date'] >= datetime.date(year=2019, month=8, day=1)].reset_index(drop=True) #фильтрую датафрейм, чтобы в него попали все события с 1 августа 2019
df_filter['date_time'].hist(bins=100)
plt.xticks(rotation = 45)
plt.show() #визуализация частот событий по датам

df_filter['date_time'].min()
df_filter['date_time'].max()

users_old = len(df['device_id_hash'].unique())
users_new = len(df_filter['device_id_hash'].unique())
print(round(((users_old-users_new)*100/users_old), 2)) #отношение числа потерянных пользователей к исходным в процентах. Мало потерей.

print(round(100-(df_filter.shape[0]*100/df.shape[0]), 2)) #был потерян 1 % событий от исходных

def translation_name(row): #функция чтобы вставить русское название события для упрощения
    name_event = row['event_name']
    s1 = ['MainScreenAppear', 'OffersScreenAppear', 'CartScreenAppear', 'PaymentScreenSuccessful', 'Tutorial']
    s2 = ['Появление Главного Экрана','Появление предложений На Экране','Появление на Экране Корзины','Появление на Экране Сообщения "Оплата прошла успешно"', 'Руководство']
    if name_event in s1:
        return s2[s1.index(name_event)]
        
df_filter['translation'] = df_filter.apply(translation_name, axis=1) #применяю функцию для одной строки

table_group_2 = df_filter.groupby('event_name').agg({'device_id_hash':'nunique'}).sort_values(by='device_id_hash', ascending=False)
table_group_2.columns = ['count_users']
table_group_2#группирую события по количеству уникальных пользователей, которые совершали то или иное событие

table_group_2['ration'] = table_group_2['count_users']/users_new
table_group_2
#отношение числа пользователей, которые выполнили это события по отношению к общему количеству уникальных пользователей

fig = go.Figure(
    go.Funnel(
        y=[
            'Открытие главного экрана',
            'Открытие списка предложений',
            'Открытие корзины',
            'Появление на Экране Сообщения "Оплата прошла успешно"'
        ],
        x=[table_group_2['count_users']['MainScreenAppear'], table_group_2['count_users']['OffersScreenAppear'],
           table_group_2['count_users']['CartScreenAppear'], table_group_2['count_users']['PaymentScreenSuccessful']], #users_new это число уникальных пользователей
    )
)
fig.show()
#строим воронку событий по уникальным пользователям

list_events = ['MainScreenAppear', 'MainScreenAppear', 'OffersScreenAppear', 'CartScreenAppear', 'PaymentScreenSuccessful']
users_on_event = [table_group_2['count_users']['MainScreenAppear'], table_group_2['count_users']['MainScreenAppear'], table_group_2['count_users']['OffersScreenAppear'],
           table_group_2['count_users']['CartScreenAppear'], table_group_2['count_users']['PaymentScreenSuccessful']]
try:
    for i in range(len(users_on_event)):
        print(f"Конверсия {list_events[i+1]} по отношению к {list_events[i]}")
        print(round((users_on_event[i+1]/users_on_event[i]), 2))
except IndexError:
    print('')
    
percent_users_from_first_to_pay = round(table_group_2['count_users']['PaymentScreenSuccessful']*100/table_group_2['count_users']['MainScreenAppear'])
print(f"{percent_users_from_first_to_pay} процентов пользователей доходят от первого события до оплаты")

table_group_3 = df_filter.groupby("exp_id").agg({'device_id_hash':'nunique'})
table_group_3.columns = ['count_users']
table_group_3

df_filter.groupby('device_id_hash').agg({'exp_id':'nunique'}).query("exp_id != 1") #проверяем, чтобы пользователи не входили сразу в нескольких группах

df_filter_246 = df_filter.query("exp_id == 246") #делаем срез данных по группам 246 и 247
df_filter_247 = df_filter.query("exp_id == 247")
uniq_users_246 = len(df_filter_246['device_id_hash'].unique())
uniq_users_247 = len(df_filter_247['device_id_hash'].unique())

table_group_246 = df_filter_246.groupby("event_name").agg({'device_id_hash':'nunique'})
table_group_247 = df_filter_247.groupby("event_name").agg({'device_id_hash':'nunique'})
table_group_246.columns = ['count_users_246']
table_group_247.columns = ['count_users_247']

users_246 = table_group_246['count_users_246'].values
users_247 = table_group_247['count_users_247'].values

def comparison_rations(successes, trials):
    alpha = 0.05  # критический уровень статистической значимости

    # пропорция успехов в первой группе:
    p1 = successes[0]/trials[0]

    # пропорция успехов во второй группе:
    p2 = successes[1]/trials[1]

    # пропорция успехов в комбинированном датасете:
    p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])

    # разница пропорций в датасетах
    difference = p1 - p2 
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(
        p_combined * (1 - p_combined) * (1 / trials[0] + 1 / trials[1])
    )

    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = st.norm(0, 1)

    p_value = (1 - distr.cdf(abs(z_value))) * 2


    if p_value < alpha:
        return (p_value, 'Отвергаем нулевую гипотезу: между долями есть значимая разница')
    else:
        return (p_value, 'Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными') 
        
 for i in range(len(users_246)):
    print("Сравнение события:", table_group_246.index[i])
    successes = [users_246[i], users_247[i]]
    trials = [uniq_users_246, uniq_users_247]
    print(comparison_rations(successes, trials))
    
for i in range(len(users_246)):
    print("Сравнение события:", table_group_246.index[i])
    successes = [users_246[i], users_247[i]]
    trials = [uniq_users_246, uniq_users_247]
    print(comparison_rations(successes, trials))
    
df_filter_248 = df_filter.query("exp_id == 248")
uniq_users_248 = len(df_filter_248['device_id_hash'].unique())


table_group_248 = df_filter_248.groupby("event_name").agg({'device_id_hash':'nunique'})
table_group_248.columns = ['count_users_248']

users_248 = table_group_248['count_users_248'].values

for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_246[i], users_248[i]]
    trials = [uniq_users_246, uniq_users_248]
    print(comparison_rations(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_247[i], users_248[i]]
    trials = [uniq_users_247, uniq_users_248]
    print(comparison_rations(successes, trials))
    
df_filter_246_247 = df_filter.query("exp_id == 246 or exp_id == 247")
uniq_users_246_247 = len(df_filter_246_247['device_id_hash'].unique())
table_group_246_247 = df_filter_246_247.groupby("event_name").agg({'device_id_hash':'nunique'})
table_group_246_247.columns = ['count_users_246_247']
users_246_247 = table_group_246_247['count_users_246_247'].values

for i in range(len(users_248)):
    print("Сравнение события:", table_group_246_247.index[i])
    successes = [users_246_247[i], users_248[i]]
    trials = [uniq_users_246_247, uniq_users_248]
    print(comparison_rations(successes, trials))
    
def comparison_rations_shidak(successes, trials):
    alpha = 1-((1-0.05)**(1/20))  # критический уровень статистической значимости

    # пропорция успехов в первой группе:
    p1 = successes[0]/trials[0]

    # пропорция успехов во второй группе:
    p2 = successes[1]/trials[1]

    # пропорция успехов в комбинированном датасете:
    p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])

    # разница пропорций в датасетах
    difference = p1 - p2 
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(
        p_combined * (1 - p_combined) * (1 / trials[0] + 1 / trials[1])
    )

    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = st.norm(0, 1)

    p_value = (1 - distr.cdf(abs(z_value))) * 2


    if p_value < alpha:
        return (p_value, 'Отвергаем нулевую гипотезу: между долями есть значимая разница')
    else:
        return (p_value, 'Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными') 
        
 def comparison_rations_bonferoni(successes, trials):
    alpha = 0.05/20  # критический уровень статистической значимости

    # пропорция успехов в первой группе:
    p1 = successes[0]/trials[0]

    # пропорция успехов во второй группе:
    p2 = successes[1]/trials[1]

    # пропорция успехов в комбинированном датасете:
    p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])

    # разница пропорций в датасетах
    difference = p1 - p2 
    # считаем статистику в ст.отклонениях стандартного нормального распределения
    z_value = difference / mth.sqrt(
        p_combined * (1 - p_combined) * (1 / trials[0] + 1 / trials[1])
    )

    # задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)
    distr = st.norm(0, 1)

    p_value = (1 - distr.cdf(abs(z_value))) * 2


    if p_value < alpha:
        return (p_value, 'Отвергаем нулевую гипотезу: между долями есть значимая разница')
    else:
        return (p_value, 'Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными') 
        
for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_246[i], users_248[i]]
    trials = [uniq_users_246, uniq_users_248]
    print(comparison_rations_bonferoni(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_246[i], users_248[i]]
    trials = [uniq_users_246, uniq_users_248]
    print(comparison_rations_shidak(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_247[i], users_248[i]]
    trials = [uniq_users_247, uniq_users_248]
    print(comparison_rations_bonferoni(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_248.index[i])
    successes = [users_247[i], users_248[i]]
    trials = [uniq_users_247, uniq_users_248]
    print(comparison_rations_shidak(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_246_247.index[i])
    successes = [users_246_247[i], users_248[i]]
    trials = [uniq_users_246_247, uniq_users_248]
    print(comparison_rations_bonferoni(successes, trials))
    
for i in range(len(users_248)):
    print("Сравнение события:", table_group_246_247.index[i])
    successes = [users_246_247[i], users_248[i]]
    trials = [uniq_users_246_247, uniq_users_248]
    print(comparison_rations_shidak(successes, trials))
